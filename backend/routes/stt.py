# routes/stt.py
# from fastapi import APIRouter
# from services.tts_stt import recognize_from_microphone

# router = APIRouter()

# @router.get("/mic")
# def transcribe_microphone():
#     try:
#         text = recognize_from_microphone()
#         return {"status": "success", "text": text}
#     except Exception as e:
#         return {"status": "error", "message": str(e)}

# stt.py
from fastapi import APIRouter
import whisper
import speech_recognition as sr
import tempfile
import os

router = APIRouter()

# Whisper ëª¨ë¸ ë¡œë”© (ìµœì´ˆ 1íšŒ)
model = whisper.load_model("small")
recognizer = sr.Recognizer()

@router.get("/mic")
def transcribe_microphone():
    try:
        with sr.Microphone(sample_rate=16000) as source:
            print("ğŸ™ ë“£ëŠ” ì¤‘... ë§í•˜ì„¸ìš”.")
            recognizer.adjust_for_ambient_noise(source)
            audio = recognizer.listen(source)
            print("ğŸ”‡ ë°œí™” ì¢…ë£Œ, ë³€í™˜ ì¤‘...")

        # ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            wav_data = audio.get_wav_data()
            f.write(wav_data)
            temp_audio_path = f.name

        result = model.transcribe(temp_audio_path, language="ko")
        os.remove(temp_audio_path)

        return {"status": "success", "text": result["text"]}

    except Exception as e:
        return {"status": "error", "message": str(e)}
